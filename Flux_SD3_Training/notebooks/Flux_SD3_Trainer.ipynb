{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# üöÄ Flux/SD3 LoRA Training\n",
    "\n",
    "**Train LoRA adapters for next-generation diffusion models:**\n",
    "- **Flux.1 Dev/Schnell**: Black Forest Labs' revolutionary diffusion transformer\n",
    "- **SD3 Medium/Large**: Stability AI's latest and greatest\n",
    "- **AuraFlow**: Community Flux variant\n",
    "- **HiDream/HunyuanDiT**: Tencent's advanced models\n",
    "\n",
    "**Memory optimized** for consumer GPUs with automatic VRAM detection and optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### üö® **WIP STATUS - PREPARE FOR CHAOS** üö®\n",
    "This notebook **will probably crash and burn** on first run. That's normal! \n",
    "\n",
    "**Current status:**\n",
    "- ‚úÖ Training configuration generation\n",
    "- ‚úÖ Memory optimization profiles\n",
    "- ‚úÖ Kohya script integration\n",
    "- üî• **Will need debugging when you test it**\n",
    "- üíÄ **Dependencies will conflict**\n",
    "- üé¢ **Welcome to the debugging adventure!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Setup and Imports (First thing that'll probably break)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add Flux_SD3_Training to path\n",
    "flux_sd3_dir = os.path.join(os.getcwd(), 'Flux_SD3_Training')\n",
    "if flux_sd3_dir not in sys.path:\n",
    "    sys.path.append(flux_sd3_dir)\n",
    "\n",
    "try:\n",
    "    # Import Flux/SD3 managers\n",
    "    from core.flux_sd3_training_manager import FluxSD3LoRAManager\n",
    "    from core.flux_sd3_dataset_manager import FluxSD3DatasetManager\n",
    "    print(\"üöÄ Flux/SD3 Training System Loaded!\")\n",
    "    print(\"üéØ Ready to train LoRAs for next-gen diffusion models\")\nexcept ImportError as e:\n",
    "    print(f\"üí• Import failed (as expected): {e}\")\n",
    "    print(\"üí° You'll need to debug the import paths first!\")\n",
    "    print(\"üîß Check that Flux_SD3_Training folder structure is correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-section",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration (Where the fun begins)\n",
    "\n",
    "Configure your Flux/SD3 LoRA training setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Flux/SD3 LoRA Configuration\n",
    "\n",
    "# Project settings\n",
    "PROJECT_NAME = \"my_flux_lora\"  # Your LoRA project name\n",
    "DATASET_PATH = \"/path/to/your/dataset\"  # Same format as SDXL training\n",
    "\n",
    "# Model selection (prepare for model download hell)\n",
    "MODEL_TYPE = \"flux_dev\"  # Options: 'flux_dev', 'flux_schnell', 'sd3_medium', 'sd3_large', 'auraflow'\n",
    "\n",
    "# Training preset\n",
    "TRAINING_PRESET = \"concept_learning\"  # Options: 'concept_learning', 'style_training', 'character_training', 'fine_detail'\n",
    "\n",
    "# Memory profile (None = auto-detect your suffering level)\n",
    "MEMORY_PROFILE = None  # Options: None, 'ultra_low_memory', 'low_memory', 'standard', 'high_performance'\n",
    "\n",
    "# Model file paths (good luck finding these!)\n",
    "MODEL_PATHS = {\n",
    "    'clip_l': '/path/to/clip_l.safetensors',  # CLIP-L text encoder\n",
    "    't5xxl': '/path/to/t5xxl.safetensors',    # T5-XXL text encoder  \n",
    "    'clip_g': '/path/to/clip_g.safetensors'   # CLIP-G (SD3 only)\n",
    "}\n",
    "\n",
    "# Advanced settings (for when basic settings fail)\n",
    "CUSTOM_SETTINGS = {\n",
    "    'network_dim': 16,      # LoRA dimension\n",
    "    'network_alpha': 8,     # LoRA alpha\n",
    "    'learning_rate': None,  # Uses preset if None\n",
    "    'epochs': None,         # Uses preset if None\n",
    "    'unet_only': False,     # Train UNet only (skip text encoders)\n",
    "}\n",
    "\n",
    "print(f\"üìù Project: {PROJECT_NAME}\")\n",
    "print(f\"ü§ñ Model: {MODEL_TYPE} (good luck!)\")\n",
    "print(f\"üéØ Training: {TRAINING_PRESET}\")\n",
    "print(f\"üì∏ Dataset: {DATASET_PATH}\")\n",
    "print(f\"üíÄ Model paths: {MODEL_PATHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-section",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Initialize Training Environment (Error cascade incoming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "init-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize managers (probably will crash here)\n",
    "    flux_trainer = FluxSD3LoRAManager()\n",
    "    flux_dataset = FluxSD3DatasetManager()\n",
    "    \n",
    "    # Display available configurations\n",
    "    print(\"\\nü§ñ Available Models (may or may not work):\")\n",
    "    for model_id, config in flux_trainer.model_configs.items():\n",
    "        print(f\"   {model_id}: {config['description']} (Req: {config['memory_base']}GB VRAM)\")\n",
    "    \n",
    "    print(\"\\nüß† Memory Profiles (choose your suffering level):\")\n",
    "    for profile_id, config in flux_trainer.memory_profiles.items():\n",
    "        print(f\"   {profile_id}: {config['description']}\")\n",
    "    \n",
    "    print(\"\\nüéØ Training Presets:\")\n",
    "    for preset_id, config in flux_trainer.training_presets.items():\n",
    "        print(f\"   {preset_id}: {config['description']}\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"üí• Initialization failed: {e}\")\n",
    "    print(\"üé¢ Welcome to debugging hell!\")\n",
    "    print(\"üí° Check your Python path and imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-section",
   "metadata": {},
   "source": [
    "## üì∏ Dataset Validation (Same as SDXL, thank god)\n",
    "\n",
    "At least the dataset part should work since it's the same format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Validate dataset (this might actually work!)\n",
    "    print(\"üîç Validating dataset...\")\n",
    "    dataset_stats = flux_dataset.validate_t5_dataset(DATASET_PATH)  # Still uses old method name, oops\n",
    "    \n",
    "    if dataset_stats['valid_pairs'] == 0:\n",
    "        print(\"‚ùå No valid image-caption pairs found!\")\n",
    "        print(\"üí° Dataset format (same as SDXL):\")\n",
    "        print(\"   - image1.jpg + image1.txt\")\n",
    "        print(\"   - image2.png + image2.txt\")\n",
    "        print(\"   - etc.\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Found {dataset_stats['valid_pairs']} valid training pairs\")\n",
    "        print(f\"üìè Average caption length: {dataset_stats['avg_caption_length']:.1f} chars\")\n",
    "        \n",
    "        if dataset_stats['max_caption_length'] > 512:\n",
    "            print(\"‚ö†Ô∏è Some captions are very long - might cause memory issues\")\n",
    "            \nexcept Exception as e:\n",
    "    print(f\"üí• Dataset validation failed: {e}\")\n",
    "    print(\"ü§î At least we expected this...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-section",
   "metadata": {},
   "source": [
    "## ü§ñ Model File Validation (Good luck finding these files)\n",
    "\n",
    "This is where things get **really fun**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Validate model files (spoiler: they won't be found)\n",
    "    print(\"üîç Validating model files...\")\n",
    "    \n",
    "    if flux_trainer.validate_model_files(MODEL_TYPE, MODEL_PATHS):\n",
    "        print(\"üéâ MIRACLE! All model files found!\")\n",
    "    else:\n",
    "        print(\"‚ùå Model files missing (as expected)\")\n",
    "        print(\"\\nüí° Where to get these files:\")\n",
    "        \n",
    "        if 'flux' in MODEL_TYPE:\n",
    "            print(\"üì• Flux model files:\")\n",
    "            print(\"   - Main model: HuggingFace black-forest-labs/FLUX.1-dev\")\n",
    "            print(\"   - CLIP-L: openai/clip-vit-large-patch14\")\n",
    "            print(\"   - T5-XXL: google/t5-v1_1-xxl\")\n",
    "            \n",
    "        elif 'sd3' in MODEL_TYPE:\n",
    "            print(\"üì• SD3 model files:\")\n",
    "            print(\"   - Main model: stabilityai/stable-diffusion-3-medium\")\n",
    "            print(\"   - CLIP-L: openai/clip-vit-large-patch14\")\n",
    "            print(\"   - CLIP-G: laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\")\n",
    "            print(\"   - T5-XXL: google/t5-v1_1-xxl\")\n",
    "        \n",
    "        print(\"\\nüéØ Update MODEL_PATHS above with correct file locations\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"üí• Model validation crashed: {e}\")\n",
    "    print(\"üé™ The circus continues!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-section",
   "metadata": {},
   "source": [
    "## üöÄ Training Configuration & Launch (The moment of truth)\n",
    "\n",
    "If you made it this far, congratulations! Now for the **real** adventure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create training configuration\n",
    "    training_config = {\n",
    "        'project_name': PROJECT_NAME,\n",
    "        'model_type': MODEL_TYPE,\n",
    "        'training_preset': TRAINING_PRESET,\n",
    "        'memory_profile': MEMORY_PROFILE,\n",
    "        **MODEL_PATHS,  # Add model paths\n",
    "        **CUSTOM_SETTINGS  # Add custom settings\n",
    "    }\n",
    "    \n",
    "    print(\"‚öôÔ∏è Generating Flux/SD3 LoRA configuration...\")\n",
    "    config_path = flux_trainer.create_training_config(training_config)\n",
    "    \n",
    "    print(f\"\\nüìÑ Configuration saved: {config_path}\")\n",
    "    print(\"\\nüöÄ Attempting to start training (hold onto your sanity)...\")\n",
    "    \n",
    "    # Prepare for training (this is where everything breaks)\n",
    "    success = flux_trainer.start_training(config_path, DATASET_PATH)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nüéâ IMPOSSIBLE! Training setup actually worked!\")\n",
    "        print(\"üìã If training runs without crashing, buy a lottery ticket\")\n",
    "        print(\"\\nüí° Next steps:\")\n",
    "        print(\"   1. Monitor training (it will probably crash at epoch 3)\")\n",
    "        print(\"   2. Debug VRAM issues\")\n",
    "        print(\"   3. Question life choices\")\n",
    "        print(\"   4. Try again with different settings\")\n",
    "        print(\"   5. Eventually get an amazing LoRA!\")\n",
    "    else:\n",
    "        print(\"\\nüí• Training setup failed (shocking!)\")\n",
    "        print(\"üé¢ Welcome to Debug Valley - population: you\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"\\nüî• SPECTACULAR FAILURE: {e}\")\n",
    "    print(\"üé™ This is where the real fun begins!\")\n",
    "    print(\"üíÄ Time to debug for the next 47 hours\")\n",
    "    \n",
    "    # Print helpful debug info\n",
    "    print(\"\\nüîß Debug checklist:\")\n",
    "    print(\"   ‚ñ° Are model files actually downloaded?\")\n",
    "    print(\"   ‚ñ° Is Derrian's backend properly installed?\")\n",
    "    print(\"   ‚ñ° Are Kohya scripts in the right location?\")\n",
    "    print(\"   ‚ñ° Do you have enough VRAM for this madness?\")\n",
    "    print(\"   ‚ñ° Are your Python dependencies conflicting?\")\n",
    "    print(\"   ‚ñ° Is your sanity still intact?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debug-section",
   "metadata": {},
   "source": [
    "## üî• Debug Information (For when everything goes wrong)\n",
    "\n",
    "When this inevitably crashes, here's some useful info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debug-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug information dump\n",
    "print(\"üîç SYSTEM DEBUG INFO:\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Flux_SD3_Training path: {flux_sd3_dir}\")\n",
    "\n",
    "# Check if critical paths exist\n",
    "critical_paths = [\n",
    "    os.path.join(os.getcwd(), 'trainer', 'derrian_backend', 'sd_scripts'),\n",
    "    os.path.join(os.getcwd(), 'Flux_SD3_Training', 'core'),\n",
    "    DATASET_PATH\n",
    "]\n",
    "\n",
    "print(\"\\nüìÅ PATH VALIDATION:\")\n",
    "for path in critical_paths:\n",
    "    exists = \"‚úÖ\" if os.path.exists(path) else \"‚ùå\"\n",
    "    print(f\"   {exists} {path}\")\n",
    "\n",
    "# Check VRAM\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        print(f\"\\nüéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ VRAM: {vram_gb:.1f}GB\")\n",
    "        \n",
    "        if vram_gb < 12:\n",
    "            print(\"‚ö†Ô∏è  WARNING: Less than 12GB VRAM - expect suffering\")\n",
    "        elif vram_gb >= 24:\n",
    "            print(\"üéâ 24GB+ VRAM detected - you might actually succeed!\")\n",
    "    else:\n",
    "        print(\"‚ùå CUDA not available - good luck with CPU training (don't)\")\nexcept:\n",
    "    print(\"‚ùå Can't detect GPU info\")\n",
    "\n",
    "print(\"\\nüí° COMMON ISSUES:\")\n",
    "print(\"   1. Model files not downloaded\")\n",
    "print(\"   2. Wrong file paths in MODEL_PATHS\")\n",
    "print(\"   3. Derrian backend not properly installed\")\n",
    "print(\"   4. VRAM too low for model + batch size\")\n",
    "print(\"   5. Dependencies conflicting (classic)\")\n",
    "print(\"   6. Kohya scripts missing or wrong version\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"   1. Fix the first error you see\")\n",
    "print(\"   2. Run again\")\n",
    "print(\"   3. Fix the next error\")\n",
    "print(\"   4. Repeat until insanity or success\")\n",
    "print(\"   5. Document your suffering for others\")\n",
    "\n",
    "print(\"\\nüèÜ REMEMBER: Every expert was once a beginner who refused to give up!\")\n",
    "print(\"(Even when faced with 47 consecutive import errors)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "footer-section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Development Roadmap (If this ever works)\n",
    "\n",
    "**Phase 1: Make it not crash**\n",
    "- [ ] Debug import issues\n",
    "- [ ] Fix model file validation\n",
    "- [ ] Resolve dependency conflicts\n",
    "- [ ] Test basic training run\n",
    "\n",
    "**Phase 2: Make it useful**\n",
    "- [ ] Memory optimization testing\n",
    "- [ ] Training progress monitoring\n",
    "- [ ] LoRA quality validation\n",
    "- [ ] Export and inference testing\n",
    "\n",
    "**Phase 3: Polish**\n",
    "- [ ] Better error handling\n",
    "- [ ] GUI improvements\n",
    "- [ ] Documentation\n",
    "- [ ] User guides (\"How to survive Flux training\")\n",
    "\n",
    "---\n",
    "\n",
    "## üí≠ Final Words\n",
    "\n",
    "This notebook **will break**. That's not a bug, it's a feature! \n",
    "\n",
    "Every error you encounter is a learning opportunity. Every crash is character building. Every successful LoRA training run is a small miracle worth celebrating.\n",
    "\n",
    "**Good luck, brave soul!** ü´°\n",
    "\n",
    "---\n",
    "\n",
    "*Flux/SD3 LoRA Training System - \"Where dreams go to debug\"*  \n",
    "*Part of the LoRA Easy Training Jupyter ecosystem*  \n",
    "*Warning: May cause temporary insanity and permanent learning*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python", 
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}