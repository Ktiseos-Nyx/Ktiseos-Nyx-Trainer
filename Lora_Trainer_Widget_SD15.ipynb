{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"assets/doro_anachiro.png\"> LoRA Trainer - SD 1.5 Training & Management \n",
    "\n",
    "This notebook contains widgets for **SD 1.5** LoRA training and post-processing:\n",
    "- **Environment setup** and SD 1.5 model downloads\n",
    "- **Training configuration** optimized for SD 1.5 architecture  \n",
    "- **Post-training utilities** (resizing, optimization)\n",
    "\n",
    "## ðŸŽ¯ SD 1.5 Advantages\n",
    "- **Lower VRAM**: Trains on 6-8GB GPUs (vs 12-24GB for SDXL)\n",
    "- **Faster training**: Smaller model, faster iterations\n",
    "- **512x512 resolution**: Standard training resolution\n",
    "- **Mature ecosystem**: Extensive model selection and community support\n",
    "\n",
    "## Prerequisites\n",
    "Complete dataset preparation in **Dataset_Maker_Widget.ipynb** first!\n",
    "\n",
    "## Instructions\n",
    "1. Run the **Setup widget** first to prepare your SD 1.5 environment\n",
    "2. Configure training parameters optimized for SD 1.5 in the **Training widget**\n",
    "3. Monitor training progress and use **utilities** as needed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"assets/OTNANGELDOROFIX.png\" width=\"32\" height=\"32\"> Setup & Models Widget - SD 1.5\n",
    "\n",
    "**Run this first!** This widget handles SD 1.5 specific setup:\n",
    "\n",
    "### Environment Setup\n",
    "- Validates your system (6-8GB VRAM recommended for SD 1.5)\n",
    "- Downloads and installs the training backend\n",
    "- Sets up directory structure\n",
    "- Detects VastAI containers for optimization\n",
    "\n",
    "### SD 1.5 Model Downloads\n",
    "- **Base models**: SD 1.5, Anything v3/v4/v5, Realistic Vision, CounterfeitXL\n",
    "- **VAE files**: SD 1.5 VAE, Anything VAE, Blessed2 VAE\n",
    "- **Tagger models**: WD14 v3 for auto-captioning\n",
    "\n",
    "### What to expect:\n",
    "- Initial setup takes 3-10 minutes (faster than SDXL)\n",
    "- Downloads ~5-8GB for full SD 1.5 setup (vs 15GB for SDXL)\n",
    "- Creates `trainer/`, `pretrained_model/`, `vae/` directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 1:** Environment Setup Widget - SD 1.5\n",
    "# Run this cell FIRST - it's required for everything else to work!\n",
    "# This downloads the SD 1.5 training backend and sets up your environment\n",
    "\n",
    "from shared_managers import create_widget\n",
    "\n",
    "# Initialize and display the setup widget with shared managers\n",
    "# The setup widget will automatically detect this is for SD 1.5 training\n",
    "setup_widget = create_widget('setup')\n",
    "setup_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"assets/doro_diamond.png\"> Training Configuration Widget - SD 1.5 Optimized\n",
    "\n",
    "**SD 1.5 training interface!** This widget provides optimized settings for SD 1.5:\n",
    "\n",
    "### <img src=\"assets/OTNDORODUSKFIXED.png\" width=\"32\" height=\"32\"> Basic Mode (SD 1.5 Optimized)\n",
    "- **Project setup**: Name, paths, SD 1.5 model selection\n",
    "- **Dataset configuration**: 512x512 resolution, optimized batch sizes for lower VRAM\n",
    "- **Network settings**: LoRA dim/alpha (recommended: 16/8 for SD 1.5)\n",
    "- **Training parameters**: SD 1.5 optimized learning rates, epochs, scheduler\n",
    "- **Live step calculator**: Target 200-800 steps for SD 1.5 (faster convergence)\n",
    "\n",
    "### <img src=\"assets/doro_syuen.png\"> Advanced Mode (Power Users) \n",
    "Enable with the **\"ðŸ§ª Enable Advanced Training Options\"** checkbox:\n",
    "\n",
    "#### <img src=\"assets/doro.png\"> Advanced Optimizers\n",
    "- **CAME**: Memory-efficient, great for SD 1.5 on lower VRAM\n",
    "- **Prodigy Plus**: Learning rate-free optimization\n",
    "- **StableAdamW**: Improved stability for SD 1.5\n",
    "- **ADOPT**: Cutting-edge research optimizer\n",
    "\n",
    "#### <img src=\"assets/OTNEARTHFIXDORO.png\" width=\"32\" height=\"32\"> LyCORIS Methods\n",
    "- **DoRA**: Higher quality adaptation (works great on SD 1.5)\n",
    "- **LoKr**: Kronecker product decomposition\n",
    "- **LoHa**: Hadamard product adaptation\n",
    "- **(IA)Â³**: Implicit attention adaptation\n",
    "- **BOFT**: Butterfly operation adaptation\n",
    "- **GLoRA**: Generalized LoRA\n",
    "\n",
    "#### <img src=\"assets/doro_grave.png\" width=\"32\" height=\"32\"> Memory Optimizations\n",
    "- **Gradient checkpointing**: Less critical for SD 1.5 but still useful\n",
    "- **Mixed precision**: fp16/bf16 training\n",
    "\n",
    "#### <img src=\"assets/doro_fubuki.png\" width=\"32\" height=\"32\"> Advanced Schedulers\n",
    "- **REX Annealing**: Warm restarts with exponential decay\n",
    "- **Schedule-Free**: Automatic learning rate adaptation\n",
    "\n",
    "### <img src=\"assets/doro_shifty.png\" width=\"32\" height=\"32\"> SD 1.5 Educational Features\n",
    "- **Real-time explanations**: Hover tooltips optimized for SD 1.5 parameters\n",
    "- **Smart recommendations**: Auto-suggests SD 1.5 optimal settings\n",
    "- **Visual warnings**: Color-coded compatibility alerts for SD 1.5\n",
    "- **Step calculator**: Live feedback optimized for SD 1.5 training speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 2:** SD 1.5 Training Configuration Widget  \n",
    "# This is where you configure ALL your SD 1.5 training settings\n",
    "# Defaults are optimized for SD 1.5 architecture and lower VRAM requirements\n",
    "\n",
    "from shared_managers import create_widget\n",
    "\n",
    "# Initialize and display the training widget with shared managers\n",
    "# The widget will automatically use SD 1.5 optimized defaults\n",
    "training_widget = create_widget('training')\n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <img src=\"assets/doro_cinderella.png\" width=\"32\" height=\"32\"> SD 1.5 Training Progress & Control\n",
    "\n",
    "**SD 1.5 training control and live monitoring** - optimized for faster SD 1.5 training:\n",
    "\n",
    "### ðŸš€ Start SD 1.5 Training Section\n",
    "- **Training Control**: Uses `train_network.py` for SD 1.5 architecture\n",
    "- **Pre-flight Check**: SD 1.5 specific validation (VRAM, resolution, etc.)\n",
    "- **Clean Interface**: No scary CLI code visible to users\n",
    "- **Smart Integration**: Automatically connects to your SD 1.5 configuration above\n",
    "\n",
    "### ðŸ“Š Live Progress Monitor (SD 1.5 Optimized)\n",
    "- **Real-time Progress**: Faster updates due to SD 1.5's quicker training\n",
    "- **Training Log**: Scrollable output with timestamps and error detection\n",
    "- **Resource Monitoring**: Lower VRAM usage monitoring for SD 1.5\n",
    "- **Auto-save Status**: Backup progress and checkpoint monitoring\n",
    "\n",
    "### How to use:\n",
    "1. **Configure** your SD 1.5 training parameters in the Training Configuration section above\n",
    "2. **Click** the \"ðŸš€ Start LoRA Training\" button in the Start Training accordion below\n",
    "3. **Monitor** live progress - SD 1.5 trains faster so expect quicker updates!\n",
    "4. **View** detailed logs and metrics throughout training\n",
    "\n",
    "### SD 1.5 Training Benefits:\n",
    "- ðŸŽ¯ **Lower VRAM**: Works on 6-8GB GPUs\n",
    "- âš¡ **Faster**: Quicker iterations and convergence\n",
    "- ðŸ“Š **Efficient**: Less compute required than SDXL\n",
    "- ðŸ”„ **Mature**: Well-tested training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 3:** SD 1.5 Training Monitor & Control\n",
    "# Run this AFTER configuring your SD 1.5 settings in Cell 2\n",
    "# This starts SD 1.5 training and shows live progress monitoring\n",
    "\n",
    "from shared_managers import get_training_manager\n",
    "from widgets.training_monitor_widget import TrainingMonitorWidget\n",
    "\n",
    "# Use the shared training manager instance\n",
    "# It will automatically detect this is SD 1.5 training and use train_network.py\n",
    "training_monitor = TrainingMonitorWidget(training_manager_instance=get_training_manager())\n",
    "\n",
    "# Now you can display the widget\n",
    "training_monitor.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”§ Utilities Widget - SD 1.5\n",
    "\n",
    "**Post-training tools** for SD 1.5 LoRA optimization and sharing:\n",
    "\n",
    "### SD 1.5 LoRA Management\n",
    "- **Resize LoRA**: Change dim/alpha after SD 1.5 training\n",
    "- **Convert formats**: Between different LoRA implementations\n",
    "- **Merge LoRAs**: Combine multiple SD 1.5 LoRAs (experimental)\n",
    "\n",
    "### Quality Analysis\n",
    "- **Dataset statistics**: Image counts, resolution analysis (512x512 focus)\n",
    "- **Training metrics**: Loss curves, learning rate plots\n",
    "- **Sample generation**: Test your SD 1.5 LoRA with sample prompts (512x512)\n",
    "\n",
    "### Publishing Tools\n",
    "- **HuggingFace upload**: Share your SD 1.5 LoRA with the community\n",
    "- **Metadata generation**: Model cards and documentation\n",
    "- **Civitai preparation**: Format for Civitai upload (SD 1.5 category)\n",
    "\n",
    "### File Management\n",
    "- **Cleanup tools**: Remove intermediate files to save space\n",
    "- **Backup creation**: Archive your SD 1.5 training setup\n",
    "- **Project organization**: Organize multiple SD 1.5 LoRA projects\n",
    "\n",
    "### When to use:\n",
    "- **After SD 1.5 training completes**: Optimize and test your LoRA\n",
    "- **Before sharing**: Prepare files for upload\n",
    "- **Project maintenance**: Clean up and organize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 4:** Post-Training Utilities for SD 1.5 (Optional)\n",
    "# Run this AFTER SD 1.5 training completes for optimization and management tools\n",
    "# Includes LoRA resizing, format conversion, HuggingFace upload, etc.\n",
    "\n",
    "from shared_managers import create_widget\n",
    "\n",
    "# Initialize and display the utilities widget with shared managers\n",
    "# The utilities will automatically detect SD 1.5 LoRAs and use appropriate settings\n",
    "utilities_widget = create_widget('utilities')\n",
    "utilities_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“š SD 1.5 Training Tips & Best Practices\n",
    "\n",
    "### SD 1.5 Recommended Settings\n",
    "```\n",
    "Character LoRA (SD 1.5):\n",
    "- Network: 16 dim / 8 alpha (balanced for SD 1.5)\n",
    "- Learning Rate: 8e-4 UNet, 1e-4 Text Encoder (slightly higher for SD 1.5)\n",
    "- Scheduler: Cosine with 3 restarts\n",
    "- Target Steps: 200-800 (faster convergence than SDXL)\n",
    "- Dataset: 15-40 images with 8-12 repeats\n",
    "- Resolution: 512x512 (native SD 1.5 resolution)\n",
    "- Batch Size: 2-4 (higher possible due to lower VRAM usage)\n",
    "\n",
    "Style LoRA (SD 1.5):\n",
    "- Network: 32 dim / 16 alpha (more capacity for style)\n",
    "- Learning Rate: 5e-4 UNet, 5e-5 Text Encoder\n",
    "- Target Steps: 400-1200\n",
    "- Dataset: 30-100 images with 5-8 repeats\n",
    "```\n",
    "\n",
    "### SD 1.5 vs SDXL Differences\n",
    "\n",
    "**SD 1.5 Advantages:**\n",
    "- **VRAM**: 6-8GB vs 12-24GB for SDXL\n",
    "- **Speed**: 2-3x faster training iterations\n",
    "- **Convergence**: Reaches good results in fewer steps\n",
    "- **Batch Size**: Can use higher batch sizes on same hardware\n",
    "- **Model Library**: Huge selection of base models available\n",
    "\n",
    "**SDXL Advantages:**\n",
    "- **Quality**: Higher detail and resolution capabilities\n",
    "- **Text**: Better text rendering and prompt adherence\n",
    "- **Modern**: More recent architecture improvements\n",
    "\n",
    "### SD 1.5 Specific Settings\n",
    "\n",
    "**Resolution Guidelines:**\n",
    "- **Primary**: 512x512 (native training resolution)\n",
    "- **Alternative**: 768x768 (higher quality, more VRAM)\n",
    "- **Avoid**: 1024x1024 (not optimal for SD 1.5 architecture)\n",
    "\n",
    "**Learning Rate Adjustments:**\n",
    "- SD 1.5 can handle slightly higher learning rates\n",
    "- UNet: 8e-4 to 1e-3 (vs 5e-4 for SDXL)\n",
    "- Text Encoder: 1e-4 to 2e-4 (vs 1e-4 for SDXL)\n",
    "\n",
    "**Memory Optimizations for SD 1.5:**\n",
    "- Gradient checkpointing less critical (SD 1.5 uses less VRAM)\n",
    "- Can use higher batch sizes (2-4 vs 1-2 for SDXL)\n",
    "- fp16 precision still recommended for speed\n",
    "\n",
    "### Common SD 1.5 Issues & Solutions\n",
    "\n",
    "**Training too fast/burning:**\n",
    "- SD 1.5 learns faster, be careful with learning rates\n",
    "- Monitor loss curves closely\n",
    "- Consider early stopping around 200-400 steps\n",
    "\n",
    "**Underfitting:**\n",
    "- Increase network capacity (dim/alpha)\n",
    "- Use more training steps\n",
    "- Check dataset quality and tags\n",
    "\n",
    "**VRAM Issues (even on SD 1.5):**\n",
    "- Reduce batch size to 1\n",
    "- Use 512x512 resolution\n",
    "- Enable gradient checkpointing\n",
    "- Consider CAME optimizer for memory savings\n",
    "\n",
    "### SD 1.5 Model Recommendations\n",
    "\n",
    "**General Purpose:**\n",
    "- **SD 1.5 Base**: Good starting point\n",
    "- **Anything v4/v5**: Anime/illustration focused\n",
    "- **Realistic Vision**: Photorealistic images\n",
    "\n",
    "**Specialized:**\n",
    "- **Counterfeit v3**: Anime characters\n",
    "- **Deliberate**: Versatile realistic/artistic\n",
    "- **DreamShaper**: Fantasy and creative content\n",
    "\n",
    "### Advanced SD 1.5 Techniques\n",
    "\n",
    "**For Anime/Character LoRAs:**\n",
    "- Use Anything v4/v5 as base\n",
    "- Focus on consistent character tagging\n",
    "- 16/8 dim/alpha usually sufficient\n",
    "\n",
    "**For Realistic LoRAs:**\n",
    "- Use Realistic Vision or similar base\n",
    "- Higher dim/alpha may be needed (32/16)\n",
    "- Pay attention to lighting and pose variety\n",
    "\n",
    "**For Style LoRAs:**\n",
    "- Consider LoCon network type\n",
    "- Higher network capacity (32/16 or 64/32)\n",
    "- More training data and longer training\n",
    "\n",
    "---\n",
    "\n",
    "*\"SD 1.5: Tried and true!\" - Happy training! ðŸš€*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}