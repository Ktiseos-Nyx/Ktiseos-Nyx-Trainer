{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 **Unified LoRA Trainer** - One Notebook to Rule Them All!\n",
    "\n",
    "**✨ Auto-detects your model type and uses the optimal Kohya training script automatically!**\n",
    "\n",
    "## 🧠 **Smart Detection System**\n",
    "- **SD 1.5/2.0**: Uses `train_network.py` \n",
    "- **SDXL**: Uses `sdxl_train_network.py`\n",
    "- **Flux**: Uses `flux_train_network.py` with bf16 precision\n",
    "- **SD3**: Uses `sd3_train_network.py` with T5 text encoder support\n",
    "\n",
    "## 🎨 **What This Notebook Does**\n",
    "1. **Cell 1**: Environment Setup & Backend Installation\n",
    "2. **Cell 2**: Universal Training Configuration (auto-adapts to your model)\n",
    "3. **Cell 3**: Training Execution & Monitoring\n",
    "4. **Cell 4**: Post-Training Utilities (resize, upload, etc.)\n",
    "\n",
    "## 🔬 **For Advanced Users**\n",
    "Need specialized features? Check out:\n",
    "- `Flux_SD3_Trainer.ipynb` - T5 text encoder fine-tuning\n",
    "- `T5_Trainer.ipynb` - Dedicated T5 training\n",
    "- Future: SimpleTuner notebooks for bleeding-edge models\n",
    "\n",
    "---\n",
    "**💡 Powered by Kohya's battle-tested library system + our user-friendly widgets!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 1:** 🏗️ Environment Setup & Backend Installation\n",
    "\n",
    "**Run this first!** Sets up the training environment and downloads the Kohya backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **CELL 1:** 🔍 Environment Validation & Quick Setup\n# Auto-validates that installer.py did its job correctly\n# Only shows setup options if something needs fixing\n\nimport os\nimport sys\nfrom shared_managers import get_setup_manager\nimport ipywidgets as widgets\nfrom IPython.display import display\n\nprint(\"🎯 UNIFIED LORA TRAINER - Environment Check...\")\nprint(\"✨ Validating installation completed by installer.py\")\nprint()\n\n# Quick environment validation\nsetup_manager = get_setup_manager()\nbackend_path = os.path.join(os.getcwd(), \"trainer\", \"derrian_backend\")\n\nif os.path.exists(backend_path) and os.path.exists(os.path.join(backend_path, \"sd_scripts\")):\n    print(\"✅ Backend installation: OK\")\n    print(\"✅ Kohya sd_scripts: OK\")\n    print(\"✅ Ready for training!\")\n    print()\n    print(\"💡 Environment is ready! Proceed to Cell 2 for training configuration.\")\nelse:\n    print(\"⚠️ Backend not properly installed!\")\n    print(\"🔧 Run: python installer.py\")\n    print(\"📖 Or check installation documentation\")\n    \n    # Only show setup widget if there's an issue\n    from widgets.setup_widget import SetupWidget\n    from shared_managers import get_model_manager\n    \n    print(\"🚨 Emergency setup widget (use only if installer.py failed):\")\n    setup_widget = SetupWidget(setup_manager, get_model_manager())\n    setup_widget.display()\n\nprint()\nprint(\"💡 This notebook automatically detects your model type and uses:\")\nprint(\"   • SD 1.5/2.0 → train_network.py\")\nprint(\"   • SDXL → sdxl_train_network.py\") \nprint(\"   • Flux → flux_train_network.py\")\nprint(\"   • SD3 → sd3_train_network.py\")\n\n# Always provide diagnostic button for troubleshooting\nprint()\nprint(\"🔍 Need to troubleshoot? Use the diagnostic button below:\")\n\ndiagnostic_button = widgets.Button(\n    description=\"🔍 Run Full Diagnostics\",\n    button_style='info',\n    tooltip=\"Run comprehensive system diagnostics\"\n)\ndiagnostic_output = widgets.Output()\n\ndef run_full_diagnostics(b):\n    diagnostic_output.clear_output()\n    with diagnostic_output:\n        print(\"🔍 COMPREHENSIVE SYSTEM DIAGNOSTICS\")\n        print(\"=\" * 50)\n        \n        # Use the setup widget's diagnostic capabilities\n        from widgets.setup_widget import SetupWidget\n        from shared_managers import get_model_manager\n        \n        setup_widget = SetupWidget(setup_manager, get_model_manager())\n        \n        # Run container detection\n        container_info = setup_widget._detect_container_environment()\n        print(f\"Environment: {container_info['environment']}\")\n        print(f\"Provider: {container_info['provider_details']['name']}\")\n        print(f\"GPU Count: {container_info['gpu_count']}\")\n        print(f\"GPU Names: {container_info['gpu_names']}\")\n        \n        # Check key paths\n        print(\"\\n📁 PATH CHECKS:\")\n        paths_to_check = [\n            (\"Project Root\", os.getcwd()),\n            (\"Backend\", backend_path),\n            (\"SD Scripts\", os.path.join(backend_path, \"sd_scripts\")),\n            (\"LyCORIS\", os.path.join(backend_path, \"lycoris\")),\n        ]\n        \n        for name, path in paths_to_check:\n            status = \"✅ EXISTS\" if os.path.exists(path) else \"❌ MISSING\"\n            print(f\"   {name}: {status}\")\n            if os.path.exists(path):\n                print(f\"      → {path}\")\n        \n        # Check system dependencies\n        print(\"\\n🔧 SYSTEM DEPENDENCIES:\")\n        import shutil\n        deps = [\"python\", \"git\", \"aria2c\"]\n        for dep in deps:\n            status = \"✅ FOUND\" if shutil.which(dep) else \"❌ MISSING\"\n            print(f\"   {dep}: {status}\")\n        \n        # Check Python packages\n        print(\"\\n📦 KEY PYTHON PACKAGES:\")\n        packages = [\"torch\", \"transformers\", \"accelerate\", \"diffusers\", \"bitsandbytes\"]\n        for pkg in packages:\n            try:\n                __import__(pkg)\n                print(f\"   {pkg}: ✅ INSTALLED\")\n            except ImportError:\n                print(f\"   {pkg}: ❌ MISSING\")\n        \n        print(\"\\n✅ Diagnostic complete!\")\n\ndiagnostic_button.on_click(run_full_diagnostics)\ndisplay(diagnostic_button, diagnostic_output)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 2:** 🎨 Universal Training Configuration\n",
    "\n",
    "**The magic happens here!** Configure your training settings and the system will automatically:\n",
    "- Detect your model type from the model path\n",
    "- Select the optimal training script\n",
    "- Apply architecture-specific optimizations\n",
    "- Use the right precision settings (fp16 for SD/SDXL, bf16 for Flux, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 2:** Universal Training Configuration Widget\n",
    "# This auto-adapts based on your model type - no manual configuration needed!\n",
    "# Uses the new Kohya-powered backend with automatic model detection\n",
    "\n",
    "from core.refactored_training_manager import HybridTrainingManager\n",
    "from widgets.training_widget import TrainingWidget\n",
    "\n",
    "print(\"🎯 UNIVERSAL TRAINING CONFIGURATION\")\n",
    "print(\"✨ Smart model detection enabled\")\n",
    "print(\"🔧 Kohya optimization system active\")\n",
    "print()\n",
    "\n",
    "# Create the unified training manager (uses Kohya backend with auto-detection)\n",
    "training_manager = HybridTrainingManager()\n",
    "training_widget = TrainingWidget(training_manager)\n",
    "\n",
    "# Display the universal configuration widget\n",
    "training_widget.display()\n",
    "\n",
    "print()\n",
    "print(\"💡 Tips:\")\n",
    "print(\"   • Just select your model file - type detection is automatic!\")\n",
    "print(\"   • Default settings are optimized for each architecture\")\n",
    "print(\"   • All Kohya optimizers and features available\")\n",
    "print(\"   • CAME optimizer auto-detects if available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 3:** 🚀 Training Execution & Real-time Monitoring\n",
    "\n",
    "**Ready to train?** This cell:\n",
    "- Uses the configuration from Cell 2\n",
    "- Automatically selects the right Kohya training script\n",
    "- Shows real-time progress with loss curves and metrics\n",
    "- Handles all the technical details behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 3:** Training Execution & Monitoring\n",
    "# Run this AFTER configuring your settings in Cell 2\n",
    "# The system automatically uses the optimal training script for your model type\n",
    "\n",
    "from shared_managers import get_training_manager\n",
    "from widgets.training_monitor_widget import TrainingMonitorWidget\n",
    "\n",
    "print(\"🚀 UNIFIED TRAINING SYSTEM - Starting...\")\n",
    "print(\"🧠 Model type will be auto-detected from your model file\")\n",
    "print(\"⚡ Optimal Kohya script will be selected automatically\")\n",
    "print(\"📊 Real-time monitoring enabled\")\n",
    "print()\n",
    "\n",
    "# Use the shared training manager instance (same as Cell 2)\n",
    "training_monitor = TrainingMonitorWidget(training_manager_instance=get_training_manager())\n",
    "\n",
    "# Display the monitoring widget\n",
    "training_monitor.display()\n",
    "\n",
    "print()\n",
    "print(\"💡 What happens automatically:\")\n",
    "print(\"   ✅ Model type detection from your model path\")\n",
    "print(\"   ✅ Optimal training script selection\")\n",
    "print(\"   ✅ Architecture-specific optimizations\")\n",
    "print(\"   ✅ Memory and precision settings\")\n",
    "print(\"   ✅ Real-time progress tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 4:** 🛠️ Post-Training Utilities\n",
    "\n",
    "**Training complete?** Use these utilities to:\n",
    "- Resize your LoRA for different sizes\n",
    "- Upload to HuggingFace Hub\n",
    "- Test your trained LoRA\n",
    "- Organize your training outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 4:** Post-Training Utilities\n",
    "# Resize, upload, and manage your trained LoRAs\n",
    "# Works with all model types automatically\n",
    "\n",
    "from shared_managers import get_utilities_manager\n",
    "from widgets.utilities_widget import UtilitiesWidget\n",
    "\n",
    "print(\"🛠️ POST-TRAINING UTILITIES\")\n",
    "print(\"📦 LoRA management and optimization tools\")\n",
    "print(\"☁️ HuggingFace Hub integration\")\n",
    "print()\n",
    "\n",
    "# Create utilities widget\n",
    "utilities_widget = UtilitiesWidget(get_utilities_manager())\n",
    "utilities_widget.display()\n",
    "\n",
    "print()\n",
    "print(\"🎉 Training Complete! Your LoRA is ready to use!\")\n",
    "print(\"💡 For advanced features, check out the specialized notebooks:\")\n",
    "print(\"   • Flux_SD3_Trainer.ipynb - T5 text encoder training\")\n",
    "print(\"   • Future SimpleTuner integration for bleeding-edge models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **📊 Optional: LoRA Step Calculator**\n",
    "\n",
    "**Want to optimize your training parameters?** This calculator helps you find the perfect settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **OPTIONAL:** LoRA Step Calculator\n",
    "# Calculate optimal training steps, learning rates, and batch sizes\n",
    "# Works for all model architectures\n",
    "\n",
    "from shared_managers import create_widget\n",
    "\n",
    "print(\"📊 LORA STEP CALCULATOR\")\n",
    "print(\"🧮 Optimize your training parameters\")\n",
    "print()\n",
    "\n",
    "calculator_widget = create_widget('calculator')\n",
    "calculator_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **🗂️ Optional: File Management**\n",
    "\n",
    "**Need to manage your training files?** Upload datasets, organize outputs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **OPTIONAL:** File Management Utilities\n# Upload datasets, manage training files, organize outputs\n\nfrom shared_managers import create_widget\n\nprint(\"🗂️ FILE MANAGEMENT SYSTEM\")\nprint(\"📁 Upload and organize training data\")\nprint()\n\nfile_manager_widget = create_widget('file_manager')\ndisplay(file_manager_widget)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎨 Optional: LoRA Inference Preview\n",
    "\n",
    "**Test your trained LoRAs directly in the notebook!** Generate images with your LoRA and see the results instantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **OPTIONAL:** LoRA Inference Preview\n",
    "# Generate images with your trained LoRAs\n",
    "\n",
    "from widgets.inference_widget import InferenceWidget\n",
    "\n",
    "print(\"🎨 LORA INFERENCE PREVIEW\")\n",
    "print(\"✨ Generate images with your trained LoRAs\")\n",
    "print()\n",
    "\n",
    "inference_widget = InferenceWidget()\n",
    "inference_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎉 **Congratulations!**\n",
    "\n",
    "You've successfully trained a LoRA using the **Unified Training System**!\n",
    "\n",
    "## **✨ What Just Happened**\n",
    "- Your model type was automatically detected\n",
    "- The optimal Kohya training script was selected\n",
    "- Architecture-specific optimizations were applied\n",
    "- Training used battle-tested Kohya backend code\n",
    "\n",
    "## **🎯 For Advanced Users**\n",
    "Need more control or specialized features? Check out:\n",
    "- **`Flux_SD3_Trainer.ipynb`** - T5 text encoder training, advanced Flux/SD3 features\n",
    "- **`T5_Trainer.ipynb`** - Dedicated T5 text encoder fine-tuning\n",
    "- **Future SimpleTuner notebooks** - For bleeding-edge models not supported by Kohya\n",
    "\n",
    "## **🤝 Contributing**\n",
    "Found a bug or want to add features? This project benefits from the entire community!\n",
    "\n",
    "---\n",
    "*Powered by Kohya-ss, LyCORIS, and Derrian Distro backend systems*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}