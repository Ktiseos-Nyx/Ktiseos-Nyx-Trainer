{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"assets/doro_anachiro.png\"> LoRA Trainer - Training & Management \n",
    "\n",
    "This notebook contains widgets for LoRA training and post-processing:\n",
    "- **Environment setup** and model downloads\n",
    "- **Training configuration** and execution  \n",
    "- **Post-training utilities** (resizing, optimization)\n",
    "\n",
    "## Prerequisites\n",
    "Complete dataset preparation in **Dataset_Maker_Widget.ipynb** first!\n",
    "\n",
    "## Instructions\n",
    "1. Run the **Setup widget** first to prepare your environment\n",
    "2. Configure training parameters in the **Training widget**\n",
    "3. Monitor training progress and use **utilities** as needed\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"assets/OTNANGELDOROFIX.png\" width=\"32\" height=\"32\"> Setup & Models Widget\n",
    "\n",
    "**Run this first!** This widget handles:\n",
    "\n",
    "### Environment Setup\n",
    "- Validates your system (GPU, VRAM, storage)\n",
    "- Downloads and installs the training backend\n",
    "- Sets up directory structure\n",
    "- Detects VastAI containers for optimization\n",
    "\n",
    "### Model Downloads\n",
    "- **Base models**: SDXL, SD 1.5 from HuggingFace or Civitai\n",
    "- **VAE files**: For improved image quality\n",
    "- **Tagger models**: WD14 v3 for auto-captioning\n",
    "\n",
    "### What to expect:\n",
    "- Initial setup takes 5-15 minutes depending on internet speed\n",
    "- Downloads ~10-15GB for full SDXL setup\n",
    "- Creates `trainer/`, `pretrained_model/`, `vae/` directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260f85330d064af5b063cfce56bc1f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2>üö© 1. Setup & Models</h2><div style='padding: 10px; border: 1px solid #6c757d; b‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from widgets.setup_widget import SetupWidget\n",
    "\n",
    "setup_widget = SetupWidget()\n",
    "setup_widget.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <img src=\"assets/doro_diamond.png\"> Training Configuration Widget\n",
    "\n",
    "**The main training interface!** This widget provides:\n",
    "\n",
    "### <img src=\"assets/OTNDORODUSKFIXED.png\" width=\"32\" height=\"32\"> Basic Mode (Beginner-Friendly)\n",
    "- **Project setup**: Name, paths, model selection\n",
    "- **Dataset configuration**: Batch size, resolution, repeats\n",
    "- **Network settings**: LoRA dim/alpha (recommended: 8/4)\n",
    "- **Training parameters**: Learning rates, epochs, scheduler\n",
    "- **Live step calculator**: Target 250-1000 steps for best results\n",
    "\n",
    "### <img src=\"assets/doro_syuen.png\"> Advanced Mode (Power Users) \n",
    "Enable with the **\"üß™ Enable Advanced Training Options\"** checkbox:\n",
    "\n",
    "#### <img src=\"assets/doro.png\"> Advanced Optimizers\n",
    "- **CAME**: Memory-efficient, great for large models\n",
    "- **Prodigy Plus**: Learning rate-free optimization\n",
    "- **StableAdamW**: Improved stability\n",
    "- **ADOPT**: Cutting-edge research optimizer\n",
    "\n",
    "#### <img src=\"assets/OTNEARTHFIXDORO.png\" width=\"32\" height=\"32\"> LyCORIS Methods\n",
    "- **DoRA**: Higher quality adaptation (2-3x slower)\n",
    "- **LoKr**: Kronecker product decomposition\n",
    "- **LoHa**: Hadamard product adaptation\n",
    "- **(IA)¬≥**: Implicit attention adaptation\n",
    "- **BOFT**: Butterfly operation adaptation\n",
    "- **GLoRA**: Generalized LoRA\n",
    "\n",
    "#### <img src=\"assets/doro_grave.png\" width=\"32\" height=\"32\"> Memory Optimizations\n",
    "- **Gradient checkpointing**: Trade compute for memory\n",
    "- **Mixed precision**: fp16/bf16 training\n",
    "\n",
    "#### <img src=\"assets/doro_fubuki.png\" width=\"32\" height=\"32\"> Advanced Schedulers\n",
    "- **REX Annealing**: Warm restarts with exponential decay\n",
    "- **Schedule-Free**: Automatic learning rate adaptation\n",
    "\n",
    "### <img src=\"assets/doro_shifty.png\" width=\"32\" height=\"32\">  Educational Features\n",
    "- **Real-time explanations**: Hover tooltips for every parameter\n",
    "- **Smart recommendations**: Auto-suggests optimal pairings\n",
    "- **Visual warnings**: Color-coded compatibility alerts\n",
    "- **Step calculator**: Live feedback on training length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Added /Users/duskfall/Downloads/Lora_Easy_Training_Jupyter/trainer to Python path for custom optimizers\n",
      "üîç Checking trainer directory contents...\n",
      "Found: []\n",
      "‚ö†Ô∏è CAME optimizer not found: No module named 'LoraEasyCustomOptimizer'\n",
      "üí° CAME optimizer not found in any expected location\n",
      "‚ö†Ô∏è REX scheduler not found: No module named 'LoraEasyCustomOptimizer'\n",
      "üí° Custom optimizers might not be available - using standard optimizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7d1b1dff7941f6a649a8ceefef3dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>‚≠ê 3. Training Configuration</h2>'), Accordion(children=(VBox(children=(HTML(val‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from widgets.training_widget import TrainingWidget\n",
    "\n",
    "training_widget = TrainingWidget() \n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <img src=\"assets/doro_cinderella.png\" width=\"32\" height=\"32\"> Training Progress & Control\n",
    "\n",
    "**Training control and live monitoring** - your one-stop training interface:\n",
    "\n",
    "### üöÄ Start Training Section\n",
    "- **Training Control**: Start button and status updates\n",
    "- **Pre-flight Check**: Validation reminders and status\n",
    "- **Clean Interface**: No scary CLI code visible to users\n",
    "- **Smart Integration**: Automatically connects to your configuration above\n",
    "\n",
    "### üìä Live Progress Monitor  \n",
    "- **Real-time Progress**: Phase monitoring, progress bars, live metrics\n",
    "- **Training Log**: Scrollable output with timestamps and error detection\n",
    "- **Resource Monitoring**: GPU usage, memory, temperature tracking\n",
    "- **Auto-save Status**: Backup progress and checkpoint monitoring\n",
    "\n",
    "### How to use:\n",
    "1. **Configure** your training parameters in the Training Configuration section above\n",
    "2. **Click** the \"üöÄ Start LoRA Training\" button in the Start Training accordion below\n",
    "3. **Monitor** live progress in the Live Progress Monitor accordion\n",
    "4. **View** detailed logs and metrics throughout training\n",
    "\n",
    "### Interface Benefits:\n",
    "- üéØ **User-friendly**: No intimidating command-line code\n",
    "- üéõÔ∏è **Organized**: Clean accordion interface with logical sections\n",
    "- üìä **Comprehensive**: Full monitoring without complexity\n",
    "- üîÑ **Integrated**: Seamlessly connects to your training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widgets.training_monitor_widget import TrainingMonitorWidget\n",
    "\n",
    "# Create and display the standalone training monitor with integrated start button\n",
    "training_monitor = TrainingMonitorWidget()\n",
    "training_monitor.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## üîß Utilities Widget\n",
    "\n",
    "**Post-training tools** for optimization and sharing:\n",
    "\n",
    "### LoRA Management\n",
    "- **Resize LoRA**: Change dim/alpha after training\n",
    "- **Convert formats**: Between different LoRA implementations\n",
    "- **Merge LoRAs**: Combine multiple LoRAs (experimental)\n",
    "\n",
    "### Quality Analysis\n",
    "- **Dataset statistics**: Image counts, resolution analysis\n",
    "- **Training metrics**: Loss curves, learning rate plots\n",
    "- **Sample generation**: Test your LoRA with sample prompts\n",
    "\n",
    "### Publishing Tools\n",
    "- **HuggingFace upload**: Share your LoRA with the community\n",
    "- **Metadata generation**: Model cards and documentation\n",
    "- **Civitai preparation**: Format for Civitai upload\n",
    "\n",
    "### File Management\n",
    "- **Cleanup tools**: Remove intermediate files to save space\n",
    "- **Backup creation**: Archive your training setup\n",
    "- **Project organization**: Organize multiple LoRA projects\n",
    "\n",
    "### When to use:\n",
    "- **After training completes**: Optimize and test your LoRA\n",
    "- **Before sharing**: Prepare files for upload\n",
    "- **Project maintenance**: Clean up and organize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widgets.utilities_widget import UtilitiesWidget\n",
    "\n",
    "utilities_widget = UtilitiesWidget()\n",
    "utilities_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Training Tips & Best Practices\n",
    "\n",
    "### Recommended Settings (Holostrawberry's Guide)\n",
    "```\n",
    "Character LoRA:\n",
    "- Network: 8 dim / 4 alpha\n",
    "- Learning Rate: 5e-4 UNet, 1e-4 Text Encoder\n",
    "- Scheduler: Cosine with 3 restarts\n",
    "- Target Steps: 250-1000\n",
    "- Dataset: 15-50 images with 5-10 repeats\n",
    "```\n",
    "\n",
    "### Common Issues & Solutions\n",
    "\n",
    "**Training too fast/slow:**\n",
    "- Adjust learning rates (higher = faster learning)\n",
    "- Change dataset repeats (more repeats = more steps)\n",
    "- Monitor loss curves in real-time\n",
    "\n",
    "**Out of VRAM:**\n",
    "- Reduce batch size to 1\n",
    "- Lower resolution (1024‚Üí768)\n",
    "- Enable gradient checkpointing\n",
    "- Use Fused Back Pass (advanced mode)\n",
    "\n",
    "**Poor quality results:**\n",
    "- Check image quality and diversity\n",
    "- Improve captions and tags\n",
    "- Try different dim/alpha ratios\n",
    "- Consider DoRA for higher quality\n",
    "\n",
    "### Advanced Techniques\n",
    "\n",
    "**For Style LoRAs:**\n",
    "- Use LoCon network type\n",
    "- Try (IA)¬≥ adaptation method\n",
    "- Lower learning rates, longer training\n",
    "\n",
    "**For Character LoRAs:**\n",
    "- Standard LoRA works best\n",
    "- Focus on consistent tagging\n",
    "- Use trigger words effectively\n",
    "\n",
    "**Memory Optimization:**\n",
    "- CAME optimizer saves ~2GB VRAM\n",
    "- Fused Back Pass reduces peaks\n",
    "- fp16 precision halves memory usage\n",
    "\n",
    "---\n",
    "\n",
    "*\"Either gonna work or blow up!\" - Happy training! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
