{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"assets/doro_anachiro.png\"> LoRA Trainer - Training & Management \n",
    "\n",
    "This notebook contains widgets for LoRA training and post-processing:\n",
    "- **Environment setup** and model downloads\n",
    "- **Training configuration** and execution  \n",
    "- **Post-training utilities** (resizing, optimization)\n",
    "\n",
    "## Prerequisites\n",
    "Complete dataset preparation in **Dataset_Maker_Widget.ipynb** first!\n",
    "\n",
    "## Instructions\n",
    "1. Run the **Setup widget** first to prepare your environment\n",
    "2. Configure training parameters in the **Training widget**\n",
    "3. Monitor training progress and use **utilities** as needed\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"assets/OTNANGELDOROFIX.png\" width=\"32\" height=\"32\"> Setup & Models Widget\n",
    "\n",
    "**Run this first!** This widget handles:\n",
    "\n",
    "### Environment Setup\n",
    "- Validates your system (GPU, VRAM, storage)\n",
    "- Downloads and installs the training backend\n",
    "- Sets up directory structure\n",
    "- Detects VastAI containers for optimization\n",
    "\n",
    "### Model Downloads\n",
    "- **Base models**: SDXL, SD 1.5 from HuggingFace or Civitai\n",
    "- **VAE files**: For improved image quality\n",
    "- **Tagger models**: WD14 v3 for auto-captioning\n",
    "\n",
    "### What to expect:\n",
    "- Initial setup takes 5-15 minutes depending on internet speed\n",
    "- Downloads ~10-15GB for full SDXL setup\n",
    "- Creates `trainer/`, `pretrained_model/`, `vae/` directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **CELL 1:** Environment Setup Widget\n# Run this cell FIRST - it's required for everything else to work!\n# This downloads the training backend and sets up your environment\n\nfrom shared_managers import create_widget\n\n# Initialize and display the setup widget with shared managers\nsetup_widget = create_widget('setup')\nsetup_widget.display()"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": "## <img src=\"assets/doro_diamond.png\"> Training Configuration Widget\n\n**The main training interface!** This widget provides:\n\n### <img src=\"assets/OTNDORODUSKFIXED.png\" width=\"32\" height=\"32\"> Basic Mode (Beginner-Friendly)\n- **Project setup**: Name, paths, model selection\n- **Dataset configuration**: Batch size, resolution, repeats\n- **Network settings**: LoRA dim/alpha (recommended: 16/8 for balanced capacity/stability)\n- **Training parameters**: Learning rates, epochs, scheduler\n- **Live step calculator**: Target 250-1000 steps for best results\n\n### <img src=\"assets/doro_syuen.png\"> Advanced Mode (Power Users) \nEnable with the **\"üß™ Enable Advanced Training Options\"** checkbox:\n\n#### <img src=\"assets/doro.png\"> Advanced Optimizers\n- **CAME**: Memory-efficient, great for large models\n- **Prodigy Plus**: Learning rate-free optimization\n- **StableAdamW**: Improved stability\n- **ADOPT**: Cutting-edge research optimizer\n\n#### <img src=\"assets/OTNEARTHFIXDORO.png\" width=\"32\" height=\"32\"> LyCORIS Methods\n- **DoRA**: Higher quality adaptation (2-3x slower)\n- **LoKr**: Kronecker product decomposition\n- **LoHa**: Hadamard product adaptation\n- **(IA)¬≥**: Implicit attention adaptation\n- **BOFT**: Butterfly operation adaptation\n- **GLoRA**: Generalized LoRA\n\n#### <img src=\"assets/doro_grave.png\" width=\"32\" height=\"32\"> Memory Optimizations\n- **Gradient checkpointing**: Trade compute for memory\n- **Mixed precision**: fp16/bf16 training\n\n#### <img src=\"assets/doro_fubuki.png\" width=\"32\" height=\"32\"> Advanced Schedulers\n- **REX Annealing**: Warm restarts with exponential decay\n- **Schedule-Free**: Automatic learning rate adaptation\n\n### <img src=\"assets/doro_shifty.png\" width=\"32\" height=\"32\">  Educational Features\n- **Real-time explanations**: Hover tooltips for every parameter\n- **Smart recommendations**: Auto-suggests optimal pairings\n- **Visual warnings**: Color-coded compatibility alerts\n- **Step calculator**: Live feedback on training length"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# **CELL 2:** Main Training Configuration Widget  \n# This is where you configure ALL your training settings\n# Fill out the forms, check the step calculator, then move to Cell 3\n\nfrom shared_managers import create_widget\n\n# Initialize and display the training widget with shared managers\ntraining_widget = create_widget('training')\ntraining_widget.display()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <img src=\"assets/doro_cinderella.png\" width=\"32\" height=\"32\"> Training Progress & Control\n",
    "\n",
    "**Training control and live monitoring** - your one-stop training interface:\n",
    "\n",
    "### üöÄ Start Training Section\n",
    "- **Training Control**: Start button and status updates\n",
    "- **Pre-flight Check**: Validation reminders and status\n",
    "- **Clean Interface**: No scary CLI code visible to users\n",
    "- **Smart Integration**: Automatically connects to your configuration above\n",
    "\n",
    "### üìä Live Progress Monitor  \n",
    "- **Real-time Progress**: Phase monitoring, progress bars, live metrics\n",
    "- **Training Log**: Scrollable output with timestamps and error detection\n",
    "- **Resource Monitoring**: GPU usage, memory, temperature tracking\n",
    "- **Auto-save Status**: Backup progress and checkpoint monitoring\n",
    "\n",
    "### How to use:\n",
    "1. **Configure** your training parameters in the Training Configuration section above\n",
    "2. **Click** the \"üöÄ Start LoRA Training\" button in the Start Training accordion below\n",
    "3. **Monitor** live progress in the Live Progress Monitor accordion\n",
    "4. **View** detailed logs and metrics throughout training\n",
    "\n",
    "### Interface Benefits:\n",
    "- üéØ **User-friendly**: No intimidating command-line code\n",
    "- üéõÔ∏è **Organized**: Clean accordion interface with logical sections\n",
    "- üìä **Comprehensive**: Full monitoring without complexity\n",
    "- üîÑ **Integrated**: Seamlessly connects to your training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **CELL 3:** Training Monitor & Control\n# Run this AFTER configuring your settings in Cell 2\n# This starts training and shows live progress monitoring\n\nfrom shared_managers import get_training_manager\nfrom widgets.training_monitor_widget import TrainingMonitorWidget\n\n# Use the shared training manager instance\ntraining_monitor = TrainingMonitorWidget(training_manager_instance=get_training_manager())\n\n# Now you can display the widget\ntraining_monitor.display()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## üîß Utilities Widget\n",
    "\n",
    "**Post-training tools** for optimization and sharing:\n",
    "\n",
    "### LoRA Management\n",
    "- **Resize LoRA**: Change dim/alpha after training\n",
    "- **Convert formats**: Between different LoRA implementations\n",
    "- **Merge LoRAs**: Combine multiple LoRAs (experimental)\n",
    "\n",
    "### Quality Analysis\n",
    "- **Dataset statistics**: Image counts, resolution analysis\n",
    "- **Training metrics**: Loss curves, learning rate plots\n",
    "- **Sample generation**: Test your LoRA with sample prompts\n",
    "\n",
    "### Publishing Tools\n",
    "- **HuggingFace upload**: Share your LoRA with the community\n",
    "- **Metadata generation**: Model cards and documentation\n",
    "- **Civitai preparation**: Format for Civitai upload\n",
    "\n",
    "### File Management\n",
    "- **Cleanup tools**: Remove intermediate files to save space\n",
    "- **Backup creation**: Archive your training setup\n",
    "- **Project organization**: Organize multiple LoRA projects\n",
    "\n",
    "### When to use:\n",
    "- **After training completes**: Optimize and test your LoRA\n",
    "- **Before sharing**: Prepare files for upload\n",
    "- **Project maintenance**: Clean up and organize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **CELL 4:** Post-Training Utilities (Optional)\n# Run this AFTER training completes for optimization and management tools\n# Includes LoRA resizing, format conversion, HuggingFace upload, etc.\n\nfrom shared_managers import create_widget\n\n# Initialize and display the utilities widget with shared managers\nutilities_widget = create_widget('utilities')\nutilities_widget.display()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## üìö Training Tips & Best Practices\n\n### Recommended Settings (Updated Based on Analysis)\n```\nCharacter LoRA:\n- Network: 16 dim / 8 alpha (balanced capacity/stability)\n- Learning Rate: 5e-4 UNet, 1e-4 Text Encoder\n- Scheduler: Cosine with 3 restarts\n- Target Steps: 250-1000\n- Dataset: 15-50 images with 5-10 repeats\n\nLyCORIS Methods:\n- Network: 16-32 dim / 8-16 alpha (more stable than regular LoRA)\n- Can handle higher dimensions and learning rates\n- Better for complex characters and detailed styles\n```\n\n### Dim/Alpha Capacity vs Stability Guide\n\n**Understanding the Trade-off:**\n- **Lower ratios (alpha/dim = 0.25)**: Very stable, may underfit small datasets\n- **Balanced ratios (alpha/dim = 0.5)**: Our default, good stability and capacity\n- **Higher ratios (alpha/dim = 1.0)**: More aggressive learning, higher burning risk\n\n**Architecture-Specific Guidelines:**\n- **Regular LoRA**: 8/4 or 16/8 - more sensitive to high ratios\n- **LyCORIS**: 16/8 or 32/16 - can handle higher dimensions safely\n- **DoRA**: Can push even higher due to superior stability\n\n### Common Issues & Solutions\n\n**Training too fast/slow:**\n- Adjust learning rates (higher = faster learning)\n- Change dataset repeats (more repeats = more steps)\n- Monitor loss curves in real-time\n\n**Out of VRAM:**\n- Reduce batch size to 1\n- Lower resolution (1024‚Üí768)\n- Enable gradient checkpointing\n- Use Fused Back Pass (advanced mode)\n\n**Poor quality results:**\n- Check image quality and diversity\n- Improve captions and tags\n- Try different dim/alpha ratios\n- Consider DoRA for higher quality\n- Ensure sufficient network capacity for your dataset\n\n**Burning/Overfitting:**\n- Lower learning rates\n- Reduce dim/alpha ratios\n- Use more conservative optimizers (CAME vs AdamW)\n- Check for v-pred model compatibility\n\n### Advanced Techniques\n\n**For Style LoRAs:**\n- Use LoCon network type\n- Try (IA)¬≥ adaptation method\n- Lower learning rates, longer training\n- Higher dim/alpha for complex artistic styles\n\n**For Character LoRAs:**\n- Standard LoRA or DoRA works best\n- Focus on consistent tagging\n- Use trigger words effectively\n- Balance dataset size with network capacity\n\n**Memory Optimization:**\n- CAME optimizer saves ~2GB VRAM\n- Fused Back Pass reduces peaks\n- fp16 precision halves memory usage\n\n**V-Prediction Model Training:**\n- Use more conservative settings than epsilon models\n- Monitor loss more carefully\n- Consider early stopping to prevent burning\n\n---\n\n*\"Either gonna work or blow up!\" - Happy training! üöÄ*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}