{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Trainer - Training & Management üöÄ\n",
    "\n",
    "This notebook contains widgets for LoRA training and post-processing:\n",
    "- **Environment setup** and model downloads\n",
    "- **Training configuration** and execution  \n",
    "- **Post-training utilities** (resizing, optimization)\n",
    "\n",
    "## Prerequisites\n",
    "Complete dataset preparation in **Dataset_Maker_Widget.ipynb** first!\n",
    "\n",
    "## Instructions\n",
    "1. Run the **Setup widget** first to prepare your environment\n",
    "2. Configure training parameters in the **Training widget**\n",
    "3. Monitor training progress and use **utilities** as needed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö© Setup & Models Widget\n",
    "\n",
    "**Run this first!** This widget handles:\n",
    "\n",
    "### Environment Setup\n",
    "- Validates your system (GPU, VRAM, storage)\n",
    "- Downloads and installs the training backend\n",
    "- Sets up directory structure\n",
    "- Detects VastAI containers for optimization\n",
    "\n",
    "### Model Downloads\n",
    "- **Base models**: SDXL, SD 1.5 from HuggingFace or Civitai\n",
    "- **VAE files**: For improved image quality\n",
    "- **Tagger models**: WD14 v3 for auto-captioning\n",
    "\n",
    "### What to expect:\n",
    "- Initial setup takes 5-15 minutes depending on internet speed\n",
    "- Downloads ~10-15GB for full SDXL setup\n",
    "- Creates `trainer/`, `pretrained_model/`, `vae/` directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widgets.setup_widget import SetupWidget\n",
    "\n",
    "setup_widget = SetupWidget()\n",
    "setup_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚≠ê Training Configuration Widget\n",
    "\n",
    "**The main training interface!** This widget provides:\n",
    "\n",
    "### Basic Mode (Beginner-Friendly)\n",
    "- **Project setup**: Name, paths, model selection\n",
    "- **Dataset configuration**: Batch size, resolution, repeats\n",
    "- **Network settings**: LoRA dim/alpha (recommended: 8/4)\n",
    "- **Training parameters**: Learning rates, epochs, scheduler\n",
    "- **Live step calculator**: Target 250-1000 steps for best results\n",
    "\n",
    "### Advanced Mode (Power Users) üß™\n",
    "Enable with the **\"üß™ Enable Advanced Training Options\"** checkbox:\n",
    "\n",
    "#### üöÄ Advanced Optimizers\n",
    "- **CAME**: Memory-efficient, great for large models\n",
    "- **Prodigy Plus**: Learning rate-free optimization\n",
    "- **StableAdamW**: Improved stability\n",
    "- **ADOPT**: Cutting-edge research optimizer\n",
    "\n",
    "#### ü¶Ñ LyCORIS Methods\n",
    "- **DoRA**: Higher quality adaptation (2-3x slower)\n",
    "- **LoKr**: Kronecker product decomposition\n",
    "- **LoHa**: Hadamard product adaptation\n",
    "- **(IA)¬≥**: Implicit attention adaptation\n",
    "- **BOFT**: Butterfly operation adaptation\n",
    "- **GLoRA**: Generalized LoRA\n",
    "\n",
    "#### üíæ Memory Optimizations\n",
    "- **Fused Back Pass**: VRAM optimization (requires batch size = 1)\n",
    "- **Gradient checkpointing**: Trade compute for memory\n",
    "- **Mixed precision**: fp16/bf16 training\n",
    "\n",
    "#### üî¨ Advanced Schedulers\n",
    "- **REX Annealing**: Warm restarts with exponential decay\n",
    "- **Schedule-Free**: Automatic learning rate adaptation\n",
    "\n",
    "### Educational Features\n",
    "- **Real-time explanations**: Hover tooltips for every parameter\n",
    "- **Smart recommendations**: Auto-suggests optimal pairings\n",
    "- **Visual warnings**: Color-coded compatibility alerts\n",
    "- **Step calculator**: Live feedback on training length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widgets.training_widget import TrainingWidget\n",
    "\n",
    "training_widget = TrainingWidget() \n",
    "training_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Utilities Widget\n",
    "\n",
    "**Post-training tools** for optimization and sharing:\n",
    "\n",
    "### LoRA Management\n",
    "- **Resize LoRA**: Change dim/alpha after training\n",
    "- **Convert formats**: Between different LoRA implementations\n",
    "- **Merge LoRAs**: Combine multiple LoRAs (experimental)\n",
    "\n",
    "### Quality Analysis\n",
    "- **Dataset statistics**: Image counts, resolution analysis\n",
    "- **Training metrics**: Loss curves, learning rate plots\n",
    "- **Sample generation**: Test your LoRA with sample prompts\n",
    "\n",
    "### Publishing Tools\n",
    "- **HuggingFace upload**: Share your LoRA with the community\n",
    "- **Metadata generation**: Model cards and documentation\n",
    "- **Civitai preparation**: Format for Civitai upload\n",
    "\n",
    "### File Management\n",
    "- **Cleanup tools**: Remove intermediate files to save space\n",
    "- **Backup creation**: Archive your training setup\n",
    "- **Project organization**: Organize multiple LoRA projects\n",
    "\n",
    "### When to use:\n",
    "- **After training completes**: Optimize and test your LoRA\n",
    "- **Before sharing**: Prepare files for upload\n",
    "- **Project maintenance**: Clean up and organize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widgets.utilities_widget import UtilitiesWidget\n",
    "\n",
    "utilities_widget = UtilitiesWidget()\n",
    "utilities_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Training Tips & Best Practices\n",
    "\n",
    "### Recommended Settings (Holostrawberry's Guide)\n",
    "```\n",
    "Character LoRA:\n",
    "- Network: 8 dim / 4 alpha\n",
    "- Learning Rate: 5e-4 UNet, 1e-4 Text Encoder\n",
    "- Scheduler: Cosine with 3 restarts\n",
    "- Target Steps: 250-1000\n",
    "- Dataset: 15-50 images with 5-10 repeats\n",
    "```\n",
    "\n",
    "### Common Issues & Solutions\n",
    "\n",
    "**Training too fast/slow:**\n",
    "- Adjust learning rates (higher = faster learning)\n",
    "- Change dataset repeats (more repeats = more steps)\n",
    "- Monitor loss curves in real-time\n",
    "\n",
    "**Out of VRAM:**\n",
    "- Reduce batch size to 1\n",
    "- Lower resolution (1024‚Üí768)\n",
    "- Enable gradient checkpointing\n",
    "- Use Fused Back Pass (advanced mode)\n",
    "\n",
    "**Poor quality results:**\n",
    "- Check image quality and diversity\n",
    "- Improve captions and tags\n",
    "- Try different dim/alpha ratios\n",
    "- Consider DoRA for higher quality\n",
    "\n",
    "### Advanced Techniques\n",
    "\n",
    "**For Style LoRAs:**\n",
    "- Use LoCon network type\n",
    "- Try (IA)¬≥ adaptation method\n",
    "- Lower learning rates, longer training\n",
    "\n",
    "**For Character LoRAs:**\n",
    "- Standard LoRA works best\n",
    "- Focus on consistent tagging\n",
    "- Use trigger words effectively\n",
    "\n",
    "**Memory Optimization:**\n",
    "- CAME optimizer saves ~2GB VRAM\n",
    "- Fused Back Pass reduces peaks\n",
    "- fp16 precision halves memory usage\n",
    "\n",
    "---\n",
    "\n",
    "*\"Either gonna work or blow up!\" - Happy training! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}